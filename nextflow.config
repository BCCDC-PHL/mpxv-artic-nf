manifest {
  author = 'connor-lab: Matt Bull, Sendu Bala. BCCDC-PHL: Dan Fornika. oicr-gsi: Jared Simpson, Michael Laszloffy. artic-network: Sam Wilkinson'
  name = 'artic-mpxv-illumina-nf'
  homePage = 'https://github.com/BioWilko/artic-mpxv-illumina-nf'
  description = 'Nextflow for running the Artic mpxv pipeline'
  mainScript = 'main.nf'
  nextflowVersion = '>=20.01.0'
  version = '1.0.0'
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.conf'

def makeFastqSearchPath ( illuminaSuffixes, fastq_exts ) {
    if ( params.directory ) {
      def fastq_searchpath = []
      for (item in illuminaSuffixes){
          for(thing in fastq_exts){
              fastq_searchpath.add(params.directory.toString() + '/**' + item.toString() + thing.toString())
          }
      }
      return fastq_searchpath
    }
}

params {

  illuminaSuffixes = ['*_R{1,2}_001', '*_R{1,2}', '*_{1,2}' ]
  fastq_exts = ['.fastq.gz', '.fq.gz']
  fastqSearchPath = makeFastqSearchPath( params.illuminaSuffixes, params.fastq_exts )

  max_memory                 = '32.GB'
  max_cpus                   = 16
  max_time                   = '12.h'

  // Boilerplate options
  // directory = false
  // prefix = false
  ref = false
  bed = false
  gff = 'NO_FILE'
  // primer_pairs_tsv = 'NO_FILE'
  // profile = false
  // help = false
  // outdir = './results'
  tracedir = "${params.outdir}/pipeline_info"

  // // depth normalization
  // skip_normalize_depth = false

  // // host filtering
  // composite_ref = false
  // viral_contig_name = 'NC_063383.1'

  // // Repo to download your primer scheme from
  // schemeRepoURL = 'https://github.com/BCCDC-PHL/artic-mpxv2022.git'

  // // Directory within schemeRepoURL that contains primer schemes
  // schemeDir = 'primer-schemes'

  // // Scheme name
  // scheme =  'MPXV'

  // // Scheme version
  // schemeVersion = 'V2.4'

  // // Target depth for bbnorm kmer-based depth normalization
  // normalizationTargetDepth = 200

  // // Minimum depth for bbnorm kmer-based depth normalization
  // normalizationMinDepth = 5

  // // Length of reads to keep after primer trimming
  // keepLen = 50

  // // Sliding window quality threshold for keeping reads after primer trimming (illumina)
  // qualThreshold = 20

  // // frequency threshold to call ambiguous variant
  // varMinFreqThreshold = 0.25
    
  // // frequency threshold for unambiguous variant
  // varFreqThreshold = 0.75

  // // Minimum coverage depth to call variant
  // varMinDepth = 10
  
}

profiles {
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup = false
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    standard {
        docker.enabled         = true
        docker.registry        = 'quay.io'
        docker.runOptions      = "--user \$(id -u):\$(id -g) --group-add 100"
        docker.userEmulation   = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    test      { includeConfig 'conf/test.conf'      }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = false
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = false
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = false
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = false
  file = "${params.tracedir}/pipeline_dag.svg"
}

def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
